<!doctypehtml>
  <html lang=en>
    <meta charset=UTF-8>
    <meta content="IE=edge" http-equiv=X-UA-Compatible>
    <meta content="width=device-width,initial-scale=1" name=viewport>
    <title>Hritij Rana</title>
    <link href=./style.css rel=stylesheet>
    <link href=https://fonts.googleapis.com rel=preconnect>
    <link href=https://fonts.gstatic.com rel=preconnect crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:display=swap" rel=stylesheet>
    <div><img src=./img-modified.png height=100 class=rotate-image width=100></div>

    

    <div class=box1></div>
    <div id="header">
        <span class="movedown">
            <a href="https://github.com/Rhriti" rel="noopener noreferrer" target="_blank">
                <img src="./github.svg" title="github" height="20">
            </a>
        </span>
    
    </div>
    <p style="margin-bottom: 0px;font-size: 30px; color: rgb(63, 63, 65); font-weight: bold;">Hritij R</p>
    <p>I am senior at NSIT,Delhi pursuing Bachelor of Technology in CS & Math. Proficient in Python programming with strong hold over CS Algorithms and fundamentals, hands-on experience in Flutter development. Currently working as a Dialogue system engineer 
    
    <table>
        <colgroup>
          <col style="max-width: 50%">
          <col style="max-width: 50%">
        </colgroup>
        <tbody>
        <tr>
          <td>
            <div class=highlights>
              <b>Grounded interaction</b><br>
              <p>
              How can we help people use language to interact with computers to carry out tasks in the world? I'm especially interested in multi-turn, task-oriented settings.
              </p>
              <ul class=collapsed class=bulletless>
                <li><a href=https://jykoh.com/search-agents>Tree Search for Language Model Agents</a> (preprint) </li>
                <li><a href=https://arxiv.org/abs/2401.13649>VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks</a> (ACL 2024) </li>
                <li><a href=https://arxiv.org/abs/2310.17140>Symbolic Planning and Code Generation for Grounded Dialogue</a> (EMNLP 2023) </li>
                <li><a href=https://arxiv.org/abs/2301.13823>Grounding Language Models to Images for Multimodal Inputs and Outputs</a> (ICML 2023)</li>
                <li><a href=https://arxiv.org/abs/2305.17216>Generating Images with Multimodal Language Models</a> (NeurIPS 2023)</li>
                <li><a href=https://webarena.dev>WebArena: A Realistic Web Environment for Building Autonomous Agents</a> (ICLR 2024)</li> 
              <li><a href=http://arxiv.org/abs/2310.11667>Sotopia: Interactive Evaluation for Social Intelligence in Language Agents</a> (ICLR 2024) <li>
                <!--
                <li><a href=https://arxiv.org/abs/2109.05042>Reference-Centric Models for Grounded Collaborative Dialogue</a> (EMNLP 2021)</li>
                -->
              </ul>
            </div>
          </td>
    
        </tr>

        </tbody>
      </table>